{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6DMxwdKZdaan"
   },
   "source": [
    "# Diabetes Challenge\n",
    "\n",
    "Your task today is to **analyze** the Kaggle \"Pima Indians Diabetes Database\" and to **predict** whether a patient has Diabetes or not.\n",
    "\n",
    "## Task:\n",
    "- Load the data from the database. The schema is called `diabetes`. To connect to the database you need to copy the `.env` file from the visualization or hands-on-ml repository into this repo. Explore the database, try to establish what the relationships between the tables are (1-1, 1-N, N-M). Explain to yourself and the group what data do you see and whether it makes sense. What JOINs are appropriate to use and why? \n",
    "- Use at least two different classification algorithms we have learned so far to predict Diabetes patients. \n",
    "- Discuss before you start with the modeling process which **evaluation metric** you choose and explain why.\n",
    "- Implement a GridSearchCV or RandomizedSearchCV to tune the hyperparameters of your model.\n",
    "- **Optional:** If you have time at the end, try to use sklearn's pipline module to encapsulate all the steps into a pipeline.\n",
    "\n",
    "Don't forget to split your data in train and test set. And analyze your final model on the test data. It might also be necessary to scale your data in order to improve the performance of some of the models.\n",
    "\n",
    "\n",
    "## Helpful links and advise:\n",
    "- [sklearn documentation on hyperparameter tuning](https://scikit-learn.org/stable/modules/grid_search.html#grid-search)\n",
    "- It might be helpful to check some sources on how to deal with imbalanced data. \n",
    "    * [8 Tactics to Combat Imbalanced Classes](https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/)\n",
    "    * [Random-Oversampling/Undersampling](https://machinelearningmastery.com/random-oversampling-and-undersampling-for-imbalanced-classification/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aFFBgjcYhrt8"
   },
   "source": [
    "# Data Description\n",
    "\n",
    "## Context\n",
    "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n",
    "\n",
    "## Acknowledgements\n",
    "Smith, J.W., Everhart, J.E., Dickson, W.C., Knowler, W.C., & Johannes, R.S. (1988). Using the ADAP learning algorithm to forecast the onset of diabetes mellitus. In Proceedings of the Symposium on Computer Applications and Medical Care (pp. 261--265). IEEE Computer Society Press.\n",
    "\n",
    "## About this dataset\n",
    "The datasets consist of several medical predictor (independent) variables and one target (dependent) variable, Outcome. Independent variables include the number of pregnancies the patient has had, their BMI, insulin level, age, and so on. For the outcome class value 1 is interpreted as \"tested positive for diabetes\".\n",
    "\n",
    "|Column Name| Description|\n",
    "|:------------|:------------|\n",
    "|Pregnancies|Number of times pregnant|\n",
    "|Glucose|Plasma glucose concentration a 2 hours in an oral glucose tolerance test|\n",
    "|BloodPressure|Diastolic blood pressure (mm Hg)|\n",
    "|SkinThickness|Triceps skin fold thickness (mm)|\n",
    "|Insulin|2-Hour serum insulin (mu U/ml)|\n",
    "|BMI|Body mass index (weight in kg/(height in m)^2)|\n",
    "|DiabetesPedigreeFunction| Diabetes pedigree function|\n",
    "|Age| Age (years)|\n",
    "|Outcome|Class variable (0 or 1) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "RSEED = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline # focus on this one\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, cross_validate\n",
    "from sklearn.metrics import roc_curve, confusion_matrix, accuracy_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>bmi</th>\n",
       "      <th>outcome</th>\n",
       "      <th>diabetespedigreefunction</th>\n",
       "      <th>skinthickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>glucose</th>\n",
       "      <th>bloodpressure</th>\n",
       "      <th>measurement_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>33.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>2022-12-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>2022-12-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>23.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>2022-12-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>2022-12-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>2022-12-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>764</td>\n",
       "      <td>63</td>\n",
       "      <td>10</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>2022-12-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>765</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>2022-12-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>766</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>2022-12-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>767</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>30.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>2022-12-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>768</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>2022-12-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  age  pregnancies   bmi  outcome  diabetespedigreefunction  \\\n",
       "0      1   50            6  33.6        1                         1   \n",
       "1      2   31            1  26.6        0                         0   \n",
       "2      3   32            8  23.3        1                         1   \n",
       "3      4   21            1  28.1        0                         0   \n",
       "4      5   33            0  43.1        1                         2   \n",
       "..   ...  ...          ...   ...      ...                       ...   \n",
       "763  764   63           10  32.9        0                         0   \n",
       "764  765   27            2  36.8        0                         0   \n",
       "765  766   30            5  26.2        0                         0   \n",
       "766  767   47            1  30.1        1                         0   \n",
       "767  768   23            1  30.4        0                         0   \n",
       "\n",
       "     skinthickness  insulin  glucose  bloodpressure measurement_date  \n",
       "0               35        0      148             72       2022-12-13  \n",
       "1               29        0       85             66       2022-12-13  \n",
       "2                0        0      183             64       2022-12-13  \n",
       "3               23       94       89             66       2022-12-13  \n",
       "4               35      168      137             40       2022-12-13  \n",
       "..             ...      ...      ...            ...              ...  \n",
       "763             48      180      101             76       2022-12-13  \n",
       "764             27        0      122             70       2022-12-13  \n",
       "765             23      112      121             72       2022-12-13  \n",
       "766              0        0      126             60       2022-12-13  \n",
       "767             31        0       93             70       2022-12-13  \n",
       "\n",
       "[768 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(\"data/diabetes_prepared.pkl\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'pregnancies', 'bmi', 'outcome', 'diabetespedigreefunction',\n",
       "       'skinthickness', 'insulin', 'glucose', 'bloodpressure'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping the unnecessary columns \n",
    "df.drop(['id', 'measurement_date'], axis=1, inplace=True)\n",
    "df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical and numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['diabetespedigreefunction']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating list for categorical predictors/features \n",
    "# (dates are also objects so if you have them in your data you would deal with them first)\n",
    "cat_features = [\"diabetespedigreefunction\"]\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'pregnancies', 'insulin', 'glucose']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating list for numerical predictors/features\n",
    "# Since 'outcome' is our target variable we will exclude this feature from this list of numerical predictors \n",
    "num_features = [\"age\", \"pregnancies\", \"insulin\", \"glucose\"]\n",
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bmi', 'bloodpressure', 'glucose', 'skinthickness']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating list for numerical predictors/features\n",
    "# Since 'outcome' is our target variable we will exclude this feature from this list of numerical predictors \n",
    "miss_features = [\"bmi\", \"bloodpressure\", \"glucose\", \"skinthickness\"]\n",
    "miss_features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 768 observations in our dataset and 8 features\n",
      "Our target vector has also 768 values\n"
     ]
    }
   ],
   "source": [
    "# Define predictors and target variable\n",
    "X = df.drop('outcome', axis=1)\n",
    "y = df['outcome']\n",
    "print(f\"We have {X.shape[0]} observations in our dataset and {X.shape[1]} features\")\n",
    "print(f\"Our target vector has also {y.shape[0]} values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test set \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=RSEED, stratify=y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (576, 8)\n",
      "X_test shape: (192, 8)\n",
      "y_train shape: (576,)\n",
      "y_test shape: (192,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Pipline for numerical features\n",
    "# Initiating Pipeline and calling one step after another\n",
    "# each step is built as a list of (key, value)\n",
    "# key is the name of the processing step\n",
    "# value is an estimator object (processing step)\n",
    "num_pipeline = Pipeline([\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "# Pipeline for missing values: in this case missing values are 0!\n",
    "miss_pipeline = Pipeline([\n",
    "    ('imputer_num', SimpleImputer(strategy='median', missing_values=0)),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Pipeline for categorical features \n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer_cat', SimpleImputer(strategy='constant')),\n",
    "    ('1hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Complete pipeline for numerical and categorical features\n",
    "# 'ColumnTranformer' applies transformers (num_pipeline/ cat_pipeline)\n",
    "# to specific columns of an array or DataFrame (num_features/cat_features)\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_features),\n",
    "    ('cat', cat_pipeline, cat_features),\n",
    "    ('miss', miss_pipeline, miss_features)\n",
    "])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictive modeling using Pipelines and GridSearch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a full pipeline with our preprocessor and a LogisticRegression Classifier\n",
    "pipe_logreg = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('logreg', LogisticRegression(max_iter=1000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions on the training set using cross validation as well as calculating the probabilities\n",
    "# cross_val_predict expects an estimator (model), X, y and nr of cv-splits (cv)\n",
    "y_train_predicted = cross_val_predict(pipe_logreg, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation scores:\n",
      "-------------------------\n",
      "Accuracy: 0.75\n",
      "Recall: 0.52\n",
      "Precision: 0.69\n"
     ]
    }
   ],
   "source": [
    "# Calculating the accuracy for the LogisticRegression Classifier \n",
    "print('Cross validation scores:')\n",
    "print('-------------------------')\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(y_train, y_train_predicted)))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y_train, y_train_predicted)))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y_train, y_train_predicted)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizing via GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining parameter space for grid-search. Since we want to access the classifier step (called 'logreg') in our pipeline \n",
    "# we have to add 'logreg__' infront of the corresponding hyperparameters. \n",
    "param_logreg = {'logreg__penalty':('l1','l2'),\n",
    "                'logreg__C': [0.001, 0.01, 0.1, 1, 10],\n",
    "                'logreg__solver': ['liblinear', 'lbfgs', 'sag']\n",
    "               }\n",
    "\n",
    "grid_logreg = GridSearchCV(pipe_logreg, param_grid=param_logreg, cv=5, scoring='recall', \n",
    "                           verbose=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[CV 1/5] END logreg__C=0.001, logreg__penalty=l1, logreg__solver=liblinear;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END logreg__C=0.001, logreg__penalty=l1, logreg__solver=liblinear;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END logreg__C=0.001, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END logreg__C=0.001, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END logreg__C=0.001, logreg__penalty=l1, logreg__solver=liblinear;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END logreg__C=0.001, logreg__penalty=l1, logreg__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END logreg__C=0.001, logreg__penalty=l1, logreg__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END logreg__C=0.001, logreg__penalty=l1, logreg__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END logreg__C=0.001, logreg__penalty=l1, logreg__solver=liblinear;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END logreg__C=0.001, logreg__penalty=l1, logreg__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END logreg__C=0.001, logreg__penalty=l1, logreg__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END logreg__C=0.001, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END logreg__C=0.001, logreg__penalty=l2, logreg__solver=liblinear;, score=0.600 total time=   0.0s\n",
      "[CV 5/5] END logreg__C=0.001, logreg__penalty=l2, logreg__solver=liblinear;, score=0.575 total time=   0.0s\n",
      "[CV 3/5] END logreg__C=0.001, logreg__penalty=l2, logreg__solver=liblinear;, score=0.675 total time=   0.0s\n",
      "[CV 4/5] END logreg__C=0.001, logreg__penalty=l2, logreg__solver=liblinear;, score=0.725 total time=   0.0s\n",
      "[CV 1/5] END logreg__C=0.001, logreg__penalty=l2, logreg__solver=liblinear;, score=0.463 total time=   0.0s\n",
      "[CV 3/5] END logreg__C=0.001, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END logreg__C=0.001, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END logreg__C=0.001, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.025 total time=   0.0s\n",
      "[CV 2/5] END logreg__C=0.001, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END logreg__C=0.001, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END logreg__C=0.001, logreg__penalty=l1, logreg__solver=liblinear;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END logreg__C=0.001, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END logreg__C=0.001, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END logreg__C=0.001, logreg__penalty=l2, logreg__solver=sag;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END logreg__C=0.001, logreg__penalty=l2, logreg__solver=sag;, score=0.025 total time=   0.0s\n",
      "[CV 3/5] END logreg__C=0.001, logreg__penalty=l2, logreg__solver=sag;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END logreg__C=0.01, logreg__penalty=l1, logreg__solver=liblinear;, score=0.700 total time=   0.0s\n",
      "[CV 1/5] END logreg__C=0.01, logreg__penalty=l1, logreg__solver=liblinear;, score=0.561 total time=   0.0s\n",
      "[CV 2/5] END logreg__C=0.01, logreg__penalty=l1, logreg__solver=liblinear;, score=0.775 total time=   0.0s\n",
      "[CV 4/5] END logreg__C=0.001, logreg__penalty=l2, logreg__solver=sag;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END logreg__C=0.001, logreg__penalty=l2, logreg__solver=sag;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END logreg__C=0.01, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END logreg__C=0.01, logreg__penalty=l1, logreg__solver=liblinear;, score=0.725 total time=   0.0s\n",
      "[CV 3/5] END logreg__C=0.01, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END logreg__C=0.01, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END logreg__C=0.01, logreg__penalty=l1, logreg__solver=liblinear;, score=0.850 total time=   0.0s\n",
      "[CV 5/5] END logreg__C=0.01, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END logreg__C=0.01, logreg__penalty=l1, logreg__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END logreg__C=0.01, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END logreg__C=0.01, logreg__penalty=l1, logreg__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END logreg__C=0.01, logreg__penalty=l1, logreg__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END logreg__C=0.01, logreg__penalty=l2, logreg__solver=liblinear;, score=0.463 total time=   0.0s\n",
      "[CV 3/5] END logreg__C=0.01, logreg__penalty=l1, logreg__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END logreg__C=0.01, logreg__penalty=l1, logreg__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END logreg__C=0.01, logreg__penalty=l2, logreg__solver=liblinear;, score=0.600 total time=   0.0s\n",
      "[CV 4/5] END logreg__C=0.01, logreg__penalty=l2, logreg__solver=liblinear;, score=0.625 total time=   0.0s\n",
      "[CV 2/5] END logreg__C=0.01, logreg__penalty=l2, logreg__solver=liblinear;, score=0.600 total time=   0.0s\n",
      "[CV 3/5] END logreg__C=0.01, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.400 total time=   0.0s\n",
      "[CV 5/5] END logreg__C=0.01, logreg__penalty=l2, logreg__solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END logreg__C=0.01, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.475 total time=   0.0s\n",
      "[CV 3/5] END logreg__C=0.1, logreg__penalty=l1, logreg__solver=liblinear;, score=0.575 total time=   0.0s\n",
      "[CV 2/5] END logreg__C=0.01, logreg__penalty=l2, logreg__solver=sag;, score=0.450 total time=   0.0s\n",
      "[CV 1/5] END logreg__C=0.1, logreg__penalty=l1, logreg__solver=liblinear;, score=0.439 total time=   0.0s\n",
      "[CV 4/5] END logreg__C=0.01, logreg__penalty=l2, logreg__solver=sag;, score=0.600 total time=   0.0s\n",
      "[CV 4/5] END logreg__C=0.1, logreg__penalty=l1, logreg__solver=liblinear;, score=0.575 total time=   0.0s\n",
      "[CV 4/5] END logreg__C=0.01, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.600 total time=   0.0s\n",
      "[CV 2/5] END logreg__C=0.1, logreg__penalty=l1, logreg__solver=liblinear;, score=0.550 total time=   0.0s\n",
      "[CV 1/5] END logreg__C=0.01, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.366 total time=   0.0s\n",
      "[CV 1/5] END logreg__C=0.01, logreg__penalty=l2, logreg__solver=sag;, score=0.366 total time=   0.0s\n",
      "[CV 2/5] END logreg__C=0.1, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END logreg__C=0.1, logreg__penalty=l1, logreg__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END logreg__C=0.1, logreg__penalty=l1, logreg__solver=liblinear;, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END logreg__C=0.01, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.450 total time=   0.0s\n",
      "[CV 4/5] END logreg__C=0.1, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END logreg__C=0.01, logreg__penalty=l2, logreg__solver=sag;, score=0.400 total time=   0.0s\n",
      "[CV 2/5] END logreg__C=0.1, logreg__penalty=l1, logreg__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END logreg__C=0.1, logreg__penalty=l1, logreg__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END logreg__C=0.1, logreg__penalty=l1, logreg__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END logreg__C=0.1, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END logreg__C=0.1, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END logreg__C=0.01, logreg__penalty=l2, logreg__solver=sag;, score=0.475 total time=   0.0s\n",
      "[CV 4/5] END logreg__C=0.1, logreg__penalty=l2, logreg__solver=liblinear;, score=0.600 total time=   0.0s\n",
      "[CV 5/5] END logreg__C=0.1, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END logreg__C=0.1, logreg__penalty=l1, logreg__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END logreg__C=0.1, logreg__penalty=l2, logreg__solver=liblinear;, score=0.600 total time=   0.0s\n",
      "[CV 4/5] END logreg__C=0.1, logreg__penalty=l2, logreg__solver=sag;, score=0.600 total time=   0.0s\n",
      "[CV 5/5] END logreg__C=0.1, logreg__penalty=l2, logreg__solver=liblinear;, score=0.475 total time=   0.0s\n",
      "[CV 5/5] END logreg__C=0.1, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.450 total time=   0.0s\n",
      "[CV 3/5] END logreg__C=1, logreg__penalty=l1, logreg__solver=liblinear;, score=0.550 total time=   0.0s\n",
      "[CV 3/5] END logreg__C=0.1, logreg__penalty=l2, logreg__solver=liblinear;, score=0.575 total time=   0.0s\n",
      "[CV 1/5] END logreg__C=0.1, logreg__penalty=l2, logreg__solver=liblinear;, score=0.439 total time=   0.0s\n",
      "[CV 2/5] END logreg__C=1, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END logreg__C=0.1, logreg__penalty=l2, logreg__solver=sag;, score=0.450 total time=   0.0s\n",
      "[CV 1/5] END logreg__C=1, logreg__penalty=l1, logreg__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END logreg__C=1, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END logreg__C=1, logreg__penalty=l2, logreg__solver=liblinear;, score=0.575 total time=   0.0s\n",
      "[CV 1/5] END logreg__C=0.1, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.439 total time=   0.0s\n",
      "[CV 5/5] END logreg__C=1, logreg__penalty=l1, logreg__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END logreg__C=0.1, logreg__penalty=l2, logreg__solver=sag;, score=0.439 total time=   0.0s\n",
      "[CV 1/5] END logreg__C=1, logreg__penalty=l1, logreg__solver=liblinear;, score=0.439 total time=   0.0s\n",
      "[CV 4/5] END logreg__C=1, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END logreg__C=1, logreg__penalty=l2, logreg__solver=liblinear;, score=0.475 total time=   0.0s\n",
      "[CV 4/5] END logreg__C=1, logreg__penalty=l1, logreg__solver=liblinear;, score=0.575 total time=   0.0s\n",
      "[CV 2/5] END logreg__C=1, logreg__penalty=l1, logreg__solver=liblinear;, score=0.575 total time=   0.0s\n",
      "[CV 2/5] END logreg__C=1, logreg__penalty=l1, logreg__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END logreg__C=1, logreg__penalty=l2, logreg__solver=liblinear;, score=0.439 total time=   0.0s\n",
      "[CV 1/5] END logreg__C=1, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.439 total time=   0.0s\n",
      "[CV 5/5] END logreg__C=1, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END logreg__C=1, logreg__penalty=l2, logreg__solver=liblinear;, score=0.575 total time=   0.0s\n",
      "[CV 3/5] END logreg__C=1, logreg__penalty=l1, logreg__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END logreg__C=0.1, logreg__penalty=l2, logreg__solver=sag;, score=0.575 total time=   0.0s\n",
      "[CV 2/5] END logreg__C=0.1, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.575 total time=   0.0s\n",
      "[CV 5/5] END logreg__C=1, logreg__penalty=l1, logreg__solver=liblinear;, score=0.475 total time=   0.0s\n",
      "[CV 4/5] END logreg__C=1, logreg__penalty=l1, logreg__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END logreg__C=1, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.575 total time=   0.0s\n",
      "[CV 3/5] END logreg__C=1, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.550 total time=   0.0s\n",
      "[CV 1/5] END logreg__C=1, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END logreg__C=1, logreg__penalty=l2, logreg__solver=sag;, score=0.575 total time=   0.0s\n",
      "[CV 4/5] END logreg__C=10, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END logreg__C=0.1, logreg__penalty=l2, logreg__solver=sag;, score=0.550 total time=   0.0s\n",
      "[CV 3/5] END logreg__C=1, logreg__penalty=l2, logreg__solver=liblinear;, score=0.550 total time=   0.0s\n",
      "[CV 1/5] END logreg__C=10, logreg__penalty=l1, logreg__solver=liblinear;, score=0.439 total time=   0.0s\n",
      "[CV 3/5] END logreg__C=10, logreg__penalty=l1, logreg__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END logreg__C=0.1, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.550 total time=   0.0s\n",
      "[CV 3/5] END logreg__C=1, logreg__penalty=l2, logreg__solver=sag;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END logreg__C=10, logreg__penalty=l1, logreg__solver=liblinear;, score=0.475 total time=   0.0s\n",
      "[CV 4/5] END logreg__C=10, logreg__penalty=l1, logreg__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END logreg__C=10, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END logreg__C=10, logreg__penalty=l1, logreg__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END logreg__C=1, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.575 total time=   0.0s\n",
      "[CV 2/5] END logreg__C=10, logreg__penalty=l1, logreg__solver=liblinear;, score=0.575 total time=   0.0s\n",
      "[CV 2/5] END logreg__C=10, logreg__penalty=l2, logreg__solver=liblinear;, score=0.575 total time=   0.0s[CV 1/5] END logreg__C=10, logreg__penalty=l1, logreg__solver=sag;, score=nan total time=   0.0s\n",
      "\n",
      "[CV 4/5] END logreg__C=1, logreg__penalty=l2, logreg__solver=sag;, score=0.575 total time=   0.0s\n",
      "[CV 4/5] END logreg__C=0.1, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END logreg__C=10, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END logreg__C=10, logreg__penalty=l1, logreg__solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END logreg__C=1, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.475 total time=   0.0s\n",
      "[CV 3/5] END logreg__C=10, logreg__penalty=l1, logreg__solver=liblinear;, score=0.550 total time=   0.0s\n",
      "[CV 1/5] END logreg__C=10, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.439 total time=   0.0s\n",
      "[CV 1/5] END logreg__C=10, logreg__penalty=l2, logreg__solver=liblinear;, score=0.439 total time=   0.0s\n",
      "[CV 2/5] END logreg__C=10, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END logreg__C=10, logreg__penalty=l2, logreg__solver=liblinear;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END logreg__C=1, logreg__penalty=l2, logreg__solver=sag;, score=0.475 total time=   0.0s\n",
      "[CV 3/5] END logreg__C=10, logreg__penalty=l1, logreg__solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END logreg__C=10, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.475 total time=   0.0s\n",
      "[CV 4/5] END logreg__C=10, logreg__penalty=l1, logreg__solver=liblinear;, score=0.575 total time=   0.0s\n",
      "[CV 2/5] END logreg__C=10, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.575 total time=   0.0s\n",
      "[CV 1/5] END logreg__C=1, logreg__penalty=l2, logreg__solver=sag;, score=0.439 total time=   0.0s\n",
      "[CV 4/5] END logreg__C=10, logreg__penalty=l2, logreg__solver=liblinear;, score=0.575 total time=   0.0s\n",
      "[CV 5/5] END logreg__C=10, logreg__penalty=l2, logreg__solver=liblinear;, score=0.475 total time=   0.0s\n",
      "[CV 3/5] END logreg__C=10, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.550 total time=   0.0s\n",
      "[CV 1/5] END logreg__C=10, logreg__penalty=l2, logreg__solver=sag;, score=0.439 total time=   0.0s\n",
      "[CV 3/5] END logreg__C=10, logreg__penalty=l2, logreg__solver=sag;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END logreg__C=10, logreg__penalty=l2, logreg__solver=sag;, score=0.475 total time=   0.0s\n",
      "[CV 2/5] END logreg__C=10, logreg__penalty=l2, logreg__solver=sag;, score=0.575 total time=   0.0s\n",
      "[CV 4/5] END logreg__C=10, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.575 total time=   0.0s\n",
      "[CV 4/5] END logreg__C=10, logreg__penalty=l2, logreg__solver=sag;, score=0.575 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isabellecarinaflaig/neuefische/ds-diabetes-challenge/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "50 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/isabellecarinaflaig/neuefische/ds-diabetes-challenge/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/isabellecarinaflaig/neuefische/ds-diabetes-challenge/.venv/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/isabellecarinaflaig/neuefische/ds-diabetes-challenge/.venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/isabellecarinaflaig/neuefische/ds-diabetes-challenge/.venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/isabellecarinaflaig/neuefische/ds-diabetes-challenge/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/isabellecarinaflaig/neuefische/ds-diabetes-challenge/.venv/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/isabellecarinaflaig/neuefische/ds-diabetes-challenge/.venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/isabellecarinaflaig/neuefische/ds-diabetes-challenge/.venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/isabellecarinaflaig/neuefische/ds-diabetes-challenge/.venv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.                nan        nan 0.60768293 0.005      0.005\n",
      " 0.72219512        nan        nan 0.55768293 0.45817073 0.45817073\n",
      " 0.52780488        nan        nan 0.53780488 0.52280488 0.52280488\n",
      " 0.52280488        nan        nan 0.52280488 0.52280488 0.52280488\n",
      " 0.52280488        nan        nan 0.52280488 0.52280488 0.52280488]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('std_scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['age',\n",
       "                                                                          'pregnancies',\n",
       "                                                                          'insulin',\n",
       "                                                                          'glucose']),\n",
       "                                                                        ('cat',\n",
       "                                                                         Pipeline(steps=[('imputer_cat',\n",
       "                                                                                          SimpleImputer(strategy='constant')),\n",
       "                                                                                         ('1hot',\n",
       "                                                                                          OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                                         ['diabetespedigreefunction']),\n",
       "                                                                        ('mi...\n",
       "                                                                         Pipeline(steps=[('imputer_num',\n",
       "                                                                                          SimpleImputer(missing_values=0,\n",
       "                                                                                                        strategy='median')),\n",
       "                                                                                         ('std_scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['bmi',\n",
       "                                                                          'bloodpressure',\n",
       "                                                                          'glucose',\n",
       "                                                                          'skinthickness'])])),\n",
       "                                       ('logreg',\n",
       "                                        LogisticRegression(max_iter=1000))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'logreg__C': [0.001, 0.01, 0.1, 1, 10],\n",
       "                         'logreg__penalty': ('l1', 'l2'),\n",
       "                         'logreg__solver': ['liblinear', 'lbfgs', 'sag']},\n",
       "             scoring='recall', verbose=5)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:\n",
      "0.00\n",
      "Best parameters:\n",
      "{'logreg__C': 0.001, 'logreg__penalty': 'l1', 'logreg__solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "# Show best parameters\n",
    "print('Best score:\\n{:.2f}'.format(grid_logreg.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(grid_logreg.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('std_scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['age', 'pregnancies',\n",
       "                                                   'insulin', 'glucose']),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('imputer_cat',\n",
       "                                                                   SimpleImputer(strategy='constant')),\n",
       "                                                                  ('1hot',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  ['diabetespedigreefunction']),\n",
       "                                                 ('miss',\n",
       "                                                  Pipeline(steps=[('imputer_num',\n",
       "                                                                   SimpleImputer(missing_values=0,\n",
       "                                                                                 strategy='median')),\n",
       "                                                                  ('std_scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['bmi', 'bloodpressure',\n",
       "                                                   'glucose',\n",
       "                                                   'skinthickness'])])),\n",
       "                ('logreg',\n",
       "                 LogisticRegression(C=0.001, max_iter=1000, penalty='l1',\n",
       "                                    solver='liblinear'))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save best model (including fitted preprocessing steps) as best_model \n",
    "best_model = grid_logreg.best_estimator_\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.65\n",
      "Recall: 0.00\n",
      "Precision: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isabellecarinaflaig/neuefische/ds-diabetes-challenge/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Calculating the accuracy, recall and precision for the test set with the optimized model\n",
    "y_test_predicted = best_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(y_test, y_test_predicted)))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y_test, y_test_predicted)))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y_test, y_test_predicted)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Diabetes-Challenge.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "dc908e6259d26511d78f3c75e137dfa2967f57eb46e5b7e69277f1b0f09f3140"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
